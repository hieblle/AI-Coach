{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cf9b85",
   "metadata": {},
   "source": [
    "# Create & search embeddings from your journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71458b",
   "metadata": {},
   "source": [
    "1. Upload and\n",
    "2. Preprocess data\n",
    "3. Create embeddings from chunked data\n",
    "4. Search and chat with your journal\n",
    "\n",
    "\n",
    "- Note: Search is only with OpenAI, not LangChain (as in Pinecone file) or something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8401237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0df4b7",
   "metadata": {},
   "source": [
    "### Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae8ab16",
   "metadata": {},
   "source": [
    "Either copy and paste journal entries below or upload a .txt file.\n",
    "\n",
    "! Text format is important. Format it in the way below,\n",
    "    (YYYY.MM.DD \\n then text of entry)\n",
    "    \n",
    "**For upload: change var \"text\" in line 35 to \"file\"**\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0e59b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short version of test journal data\n",
    "text = f\"\"\"\n",
    "2023.04.13\n",
    "Heute ist ein anstrengender Tag. Ich fühle mich seit ein paar Tagen sehr gestresst und kann kaum schlafen. In der Nacht wache ich ständig auf und meine Gedanken kreisen ununterbrochen um all die Dinge, die ich noch erledigen muss. Ich habe das Gefühl, dass ich keine Energie mehr habe und bin deshalb heute den ganzen Tag müde und unkonzentriert. \n",
    "Ich hoffe, dass sich das bald ändert und ich wieder zu meiner alten Energie zurückfinde.\n",
    "\n",
    "2023.04.14\n",
    "Heute geht es mir schon etwas besser. Ich habe gestern Abend ein paar Entspannungsübungen gemacht und konnte dadurch besser schlafen. Meine Gedanken sind immer noch etwas chaotisch, aber ich habe das Gefühl, dass ich langsam wieder Kontrolle darüber bekomme. \n",
    "Ich habe heute auch schon ein paar Dinge von meiner To-Do-Liste abhaken können, was mir ein gutes Gefühl gibt.\n",
    "\n",
    "2023.04.15\n",
    "Ich bin wirklich stolz auf mich, denn ich habe heute schon sehr viel geschafft. Ich fühle mich energiegeladen und produktiv. Die Entspannungsübungen scheinen zu helfen und ich kann meine Gedanken besser sortieren. Ich habe sogar schon anfangen können, an einem neuen Projekt zu arbeiten, auf das ich mich schon seit Wochen freue. Es fühlt sich gut an, wieder in die richtige Richtung zu gehen.\n",
    "\n",
    "2023.04.16\n",
    "Ich bin so froh, dass ich die letzten Tage so viel Energie hatte. Es hat mir geholfen, die Dinge, die ich schon lange vor mir hergeschoben habe, endlich anzugehen. Heute habe ich fast alles von meiner To-Do-Liste erledigt und fühle mich unglaublich zufrieden. Ich habe das Gefühl, dass ich meine alte Kraft zurückgewonnen habe und bin optimistisch für die Zukunft.\n",
    "\n",
    "2023.04.17\n",
    "Heute ist ein guter Tag. Ich fühle mich ausgeglichen und glücklich. Die letzten Tage haben mir gezeigt, dass ich auch in schwierigen Situationen durchhalten kann. \n",
    "Ich habe gelernt, dass es wichtig ist, auf mich selbst zu achten und mir Zeit für Entspannung und Regeneration zu nehmen. Ich bin dankbar für alles, was ich erreicht habe und freue mich auf das, was noch kommt.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b23f8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('journals/Journal-short.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46e5b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define openai api key and embedding model\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "API_0 = os.getenv('OPENAI_API_KEY')\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "path_embeddings = \"embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d9b740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain: initialize OpenAI Embeddings Model + create embeddings\n",
    "embeddings = OpenAIEmbeddings(model_name=\"ada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64e4b12",
   "metadata": {},
   "source": [
    "### Preprocessing the text\n",
    "\n",
    "1. Split entries and \n",
    "2. Chunk entries into smaller pieces\n",
    "\n",
    "    The result depends heavily on the setting of the chunking size and overlap. \n",
    "    Change length for different results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4a804bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(content):\n",
    "    \"\"\"Split content into entries based on date pattern and return a Pandas DataFrame.\n",
    "       content: string with journal entries\n",
    "       df: Pandas DataFrame with dates and entries\n",
    "       \n",
    "       WORKS ONLY WITH YYYY.MM.DD FORMAT\"\"\"\n",
    "    # Define a regular expression pattern to match dates\n",
    "    date_pattern = r'\\d{4}.\\d{2}.\\d{2}'\n",
    "\n",
    "    # Split the content based on the date pattern\n",
    "    entries = re.split(date_pattern, content)\n",
    "\n",
    "    # Extract dates from the content\n",
    "    dates = re.findall(date_pattern, content)\n",
    "\n",
    "    # Create a dictionary with dates and corresponding entries\n",
    "    data = {'Date': dates, 'Text': [entry.strip() for entry in entries[1:]]}\n",
    " \n",
    "    # Create a Pandas DataFrame from the dictionary and return it\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9c3a17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split entries into chunks using langchain\n",
    "def langchain_textsplitter(content_entry):\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 100, #change\n",
    "        chunk_overlap = 20, #change\n",
    "    )\n",
    "    \n",
    "    text_array = []\n",
    "    texts = text_splitter.create_documents([content_entry])\n",
    "    for chunk in texts:\n",
    "        text_array.append(chunk.page_content)\n",
    "\n",
    "    return text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "132c6f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>Heute ist ein anstrengender Tag. Ich fühle mic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023.04.14</td>\n",
       "      <td>Heute geht es mir schon etwas besser. Ich habe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023.04.15</td>\n",
       "      <td>Ich bin wirklich stolz auf mich, denn ich habe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023.04.16</td>\n",
       "      <td>Ich bin so froh, dass ich die letzten Tage so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023.04.17</td>\n",
       "      <td>Heute ist ein guter Tag. Ich fühle mich ausgeg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text\n",
       "0  2023.04.13  Heute ist ein anstrengender Tag. Ich fühle mic...\n",
       "1  2023.04.14  Heute geht es mir schon etwas besser. Ich habe...\n",
       "2  2023.04.15  Ich bin wirklich stolz auf mich, denn ich habe...\n",
       "3  2023.04.16  Ich bin so froh, dass ich die letzten Tage so ...\n",
       "4  2023.04.17  Heute ist ein guter Tag. Ich fühle mich ausgeg..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = split_text(text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c985a3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>Heute ist ein anstrengender Tag. Ich fühle mic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>und kann kaum schlafen. In der Nacht wache ich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>ununterbrochen um all die Dinge, die ich noch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>dass ich keine Energie mehr habe und bin desha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>Ich hoffe, dass sich das bald ändert und ich w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text\n",
       "0  2023.04.13  Heute ist ein anstrengender Tag. Ich fühle mic...\n",
       "1  2023.04.13  und kann kaum schlafen. In der Nacht wache ich...\n",
       "2  2023.04.13  ununterbrochen um all die Dinge, die ich noch ...\n",
       "3  2023.04.13  dass ich keine Energie mehr habe und bin desha...\n",
       "4  2023.04.13  Ich hoffe, dass sich das bald ändert und ich w..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_df = pd.DataFrame(columns=['Date', 'Text'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # split text into chunks, return: list of strings\n",
    "    chunks = langchain_textsplitter(row['Text'])\n",
    "    date_vector = [row['Date']]*len(chunks)\n",
    "    # concatenate in new dataframe\n",
    "    chunked_df = pd.concat([chunked_df, pd.DataFrame({'Date': date_vector, 'Text': chunks})], ignore_index = True)\n",
    "\n",
    "chunked_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6609d7a",
   "metadata": {},
   "source": [
    "### Create Embeddings & store them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b603e54",
   "metadata": {},
   "source": [
    "Now create embeddings from the chunks.\n",
    "**For large datasets it can take a while!**\n",
    "\n",
    "Therefore generate once and save it as CSV-file.\n",
    "\n",
    "TODO:\n",
    "- compare results from Langchain, OpenAI and Open Source models similar to Word2Vec or Sent2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da713858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>Heute ist ein anstrengender Tag. Ich fühle mic...</td>\n",
       "      <td>[-0.013216842897236347, 0.021550197154283524, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>und kann kaum schlafen. In der Nacht wache ich...</td>\n",
       "      <td>[0.003639327362179756, -0.0006552351405844092,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>ununterbrochen um all die Dinge, die ich noch ...</td>\n",
       "      <td>[-0.02012534998357296, -0.016028128564357758, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>dass ich keine Energie mehr habe und bin desha...</td>\n",
       "      <td>[-0.015418408438563347, 0.0031841034069657326,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023.04.13</td>\n",
       "      <td>Ich hoffe, dass sich das bald ändert und ich w...</td>\n",
       "      <td>[2.216765278717503e-05, -0.017116189002990723,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               Text  \\\n",
       "0  2023.04.13  Heute ist ein anstrengender Tag. Ich fühle mic...   \n",
       "1  2023.04.13  und kann kaum schlafen. In der Nacht wache ich...   \n",
       "2  2023.04.13  ununterbrochen um all die Dinge, die ich noch ...   \n",
       "3  2023.04.13  dass ich keine Energie mehr habe und bin desha...   \n",
       "4  2023.04.13  Ich hoffe, dass sich das bald ändert und ich w...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.013216842897236347, 0.021550197154283524, ...  \n",
       "1  [0.003639327362179756, -0.0006552351405844092,...  \n",
       "2  [-0.02012534998357296, -0.016028128564357758, ...  \n",
       "3  [-0.015418408438563347, 0.0031841034069657326,...  \n",
       "4  [2.216765278717503e-05, -0.017116189002990723,...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_df['embedding'] = chunked_df['Text'].apply(lambda x: get_embedding(x, engine=EMBEDDING_MODEL))\n",
    "chunked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44b7b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .csv to use it later, if wanted\n",
    "chunked_df.to_csv('journal_embedding.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757352bc",
   "metadata": {},
   "source": [
    "# Chat & Search\n",
    "\n",
    "1. Set the hyperparamters according to your needs and questions.\n",
    "2. Use OpenAIs GPT to generate an readable answer from search result.\n",
    "\n",
    "! Language ! \n",
    "\\\\\\\n",
    "Side note: If the journal is in german, the search term should also be. Otherwise the result of cosine similarity could get worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19dcf4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to search in embeddings\n",
    "def search(df, search_term, n=3):\n",
    "    \"\"\" \n",
    "    df: dataframe with embeddings\n",
    "    search_term: string to search for\n",
    "    n: number of results to return\n",
    "    \"\"\"\n",
    "    # convert embeddings to numpy array\n",
    "    #df[\"embedding\"] = df[\"embedding\"].apply(eval).apply(np.array)\n",
    "\n",
    "    # get embedding of search term\n",
    "    search_embeddings = get_embedding(search_term, engine=EMBEDDING_MODEL)\n",
    "\n",
    "    # calculate cosine similarity\n",
    "    df[\"similarity\"] = df[\"embedding\"].apply(lambda x: cosine_similarity(x, search_embeddings))\n",
    "\n",
    "    # sort by similarity and return top n\n",
    "    return df.sort_values(\"similarity\", ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfc167",
   "metadata": {},
   "source": [
    "Define OpenAI call-function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "180c75af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4\", temperature=0): # gpt-3.5-turbo\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        messages = messages,\n",
    "        temperature = temperature,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e2b198bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: try different models, from \"gpt-3.5-turbo\", anthropics \"claude\" to open source models on hugging face."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e3d4a",
   "metadata": {},
   "source": [
    "### Hyperparameter setting: \n",
    "- How much similar vectors you want gpt to compare for an answer?\n",
    "- What is your search-term?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2d52839b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023.04.14</td>\n",
       "      <td>was mir ein gutes Gefühl gibt.</td>\n",
       "      <td>[-0.005818309728056192, -0.017997801303863525,...</td>\n",
       "      <td>0.785841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023.04.15</td>\n",
       "      <td>freue. Es fühlt sich gut an, wieder in die ric...</td>\n",
       "      <td>[0.02654009684920311, -0.01804625801742077, -0...</td>\n",
       "      <td>0.777955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023.04.16</td>\n",
       "      <td>zufrieden. Ich habe das Gefühl, dass ich meine...</td>\n",
       "      <td>[-0.00176370854023844, -0.027162054553627968, ...</td>\n",
       "      <td>0.768509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023.04.15</td>\n",
       "      <td>Ich bin wirklich stolz auf mich, denn ich habe...</td>\n",
       "      <td>[-0.004994497634470463, -0.0016195483040064573...</td>\n",
       "      <td>0.759255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023.04.17</td>\n",
       "      <td>erreicht habe und freue mich auf das, was noch...</td>\n",
       "      <td>[0.008538960479199886, -0.03639346361160278, -...</td>\n",
       "      <td>0.749236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                               Text  \\\n",
       "9   2023.04.14                     was mir ein gutes Gefühl gibt.   \n",
       "14  2023.04.15  freue. Es fühlt sich gut an, wieder in die ric...   \n",
       "18  2023.04.16  zufrieden. Ich habe das Gefühl, dass ich meine...   \n",
       "10  2023.04.15  Ich bin wirklich stolz auf mich, denn ich habe...   \n",
       "24  2023.04.17  erreicht habe und freue mich auf das, was noch...   \n",
       "\n",
       "                                            embedding  similarity  \n",
       "9   [-0.005818309728056192, -0.017997801303863525,...    0.785841  \n",
       "14  [0.02654009684920311, -0.01804625801742077, -0...    0.777955  \n",
       "18  [-0.00176370854023844, -0.027162054553627968, ...    0.768509  \n",
       "10  [-0.004994497634470463, -0.0016195483040064573...    0.759255  \n",
       "24  [0.008538960479199886, -0.03639346361160278, -...    0.749236  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_most_similar = 5\n",
    "query = \"Why is the author feeling awesome?\" # change\n",
    "most_similar = search(chunked_df, query, num_most_similar)\n",
    "most_similar \n",
    "# outputs the most relevant parts of your journal. \n",
    "# can be fine-tuned by change the chunking length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c1ccd",
   "metadata": {},
   "source": [
    "### Result:\n",
    "\n",
    "- specifying the prompt\n",
    "- create answer out of combined outputs from most relevant search results (cos-sim)\n",
    "\n",
    "Todo: manually try different similarity calculation methods. does the result change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b7ed1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your question was: Why is the author feeling awesome? \n",
      "\n",
      "The anwer according to your journal is: \n",
      "The author is feeling awesome because he is making progress and moving in the right direction. He feels like he has regained his old strength and is optimistic about the future. He is proud of what he has achieved so far and is looking forward to what is to come.\n"
     ]
    }
   ],
   "source": [
    "conc_text = '\\n\\n'.join(most_similar[\"Text\"].tolist())\n",
    "prompt = f\"\"\"\n",
    "Take the users query and answer it by including what the user has written\n",
    "in his journal.\n",
    "query: '{query}'\n",
    "journal parts: '{conc_text}'\n",
    "\n",
    "\"\"\"\n",
    "print(f'Your question was: {query} \\n\\nThe anwer according to your journal is: \\n{get_completion(prompt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "189165b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without loading data every time: change search function, maybe create copy of df and convert this. Otherwise: Error trying converting df['embeddings'] again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f40aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same process, different prompt\n",
    "prompt2 = f\"\"\"You are in the position of a therapist.\n",
    "            The patient asks you a question. You also get important parts of the journal of the user. Answer this question based on the information from parts of the journal given below.\n",
    "            Question: {query}\n",
    "            Important parts of journal: {conc_text}\n",
    "\n",
    "            Goals:\n",
    "            1. Help people to overcome the things which are holding them back.\n",
    "            2. Discover recurring patterns.\n",
    "            Answer:\n",
    "\n",
    "\n",
    "            Example\n",
    "            Question: Why was I feeling so good?\n",
    "            Important parts of journal: I've meditated a lot. Read a lot.\n",
    "            Answer: Because meditation and reading were core habits in your life.\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5623a47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your question was: Why is the author feeling awesome? \n",
      "\n",
      "The anwer according to your journal is: \n",
      "The author is feeling awesome because they are making progress and moving in the right direction. They feel they have regained their old strength and are optimistic about the future. They are proud of what they have accomplished so far and are looking forward to what is to come.\n"
     ]
    }
   ],
   "source": [
    "print(f'Your question was: {query} \\n\\nThe anwer according to your journal is: \\n{get_completion(prompt2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9164b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: build chatwindow\n",
    "# ! use from other file and include search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f5757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
